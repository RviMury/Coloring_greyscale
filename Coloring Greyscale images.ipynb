{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Download 100 images of each of three category\n",
    "from bing_image_downloader import downloader\n",
    "downloader.download('Green Parks', limit=100,  output_dir='dataset1',\n",
    "dadult_filter_off=True, force_replace=False, timeout=60)\n",
    "\n",
    "downloader.download('Deserts', limit=100,  output_dir='dataset1',\n",
    "adult_filter_off=True, force_replace=False, timeout=60)\n",
    "\n",
    "downloader.download('Sunsets', limit=100,  output_dir='dataset1',\n",
    "adult_filter_off=True, force_replace=False, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download Necessary Imports\n",
    "from keras.layers import Conv2D, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from skimage.io import imsave, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset\\\\'\n",
    "\n",
    "#Normalize images - divide by 255\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#Resize images\n",
    "train = train_datagen.flow_from_directory(path, target_size=(256, 256), batch_size=512, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating X, Y vectors\n",
    "X =[]\n",
    "Y =[]\n",
    "for img in train[0]:\n",
    "  try:\n",
    "      lab = rgb2lab(img)\n",
    "      X.append(lab[:,:,0]) \n",
    "      Y.append(lab[:,:,1:] / 128) #A and B values range from -127 to 128, \n",
    "      \n",
    "  except:\n",
    "     print('error')\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(X.shape+(1,)) #dimensions to be the same for X and Y\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(width, height, channels=1):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2, input_shape=(width, height, channels)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "\n",
    "    #Decoder\n",
    "    #Decoder\n",
    "    #Note: For the last layer we use tanh instead of Relu. \n",
    "    #This is because we are colorizing the image in this layer using 2 filters, A and B.\n",
    "    #A and B values range between -1 and 1 so tanh (or hyperbolic tangent) is used\n",
    "    #as it also has the range between -1 and 1. \n",
    "    #Other functions go from 0 to 1.\n",
    "    model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.compile(optimizer='adam', loss='mse' , metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorize=define_model(256,256,1)\n",
    "trained_model=colorize.fit(X,Y,validation_split=0.2, epochs=50, batch_size=16)\n",
    "#colorize.save('colorize_autoencoder_50_epochs.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = trained_model.history['loss']\n",
    "val_loss = trained_model.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = trained_model.history['accuracy']\n",
    "val_acc = trained_model.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_results(path):\n",
    "    img1_grey=[]\n",
    "\n",
    "    img1=img_to_array(load_img(path))\n",
    "    img1 = resize(img1 ,(256,256))\n",
    "    img1_grey.append(img1)\n",
    "\n",
    "    img1_grey = np.array(img1_grey, dtype=float)\n",
    "    img1_grey = rgb2lab(1.0/255*img1_grey)[:,:,:,0]\n",
    "    img1_grey = img1_grey.reshape(img1_grey.shape+(1,))\n",
    "\n",
    "    output1 = colorize.predict(img1_grey)\n",
    "    output1 = output1*128\n",
    "\n",
    "    result = np.zeros((256, 256, 3))\n",
    "    result[:,:,0] = img1_grey[0][:,:,0]\n",
    "    result[:,:,1:] = output1[0]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax = axes.ravel()\n",
    "    ax[0].imshow(img1/255)\n",
    "    ax[0].set_title('Grey Image')\n",
    "    ax[1].imshow(lab2rgb(result))\n",
    "    ax[1].set_title('Colored Image')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_results('try images\\img2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mood_gender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
